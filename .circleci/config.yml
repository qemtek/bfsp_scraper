version: 2.1
jobs:
  build-and-scrape:
    working_directory: ~/project
    docker:
      - image: circleci/python:3.7.2
    steps:
      - checkout
      - run:
          command: |
            # Setup environment, install dependencies
            virtualenv venv
            . venv/bin/activate
            pip install --upgrade pip
            pip install -r requirements.txt
            export COUNTRIES='uk,ire'
            export TYPES='win,place'
            export S3_BUCKET='betfair-sp'
            export AWS_GLUE_DB='finish-time-predict'
            export AWS_GLUE_TABLE='betfair-sp'
            export PROJECT_DIR=/home/circleci/project/bfsp_scraper
            export PYTHONPATH=/home/circleci/project
            AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
            AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
            # Run daily updates
            python3 ./bfsp_scraper/get_yesterdays_data.py
  crawl-tables:
    working_directory: ~/project
    docker:
      - image: circleci/python:3.7.2
    steps:
      - checkout
      - run:
          command: |
            # Setup environment, install dependencies
            python3 ./bfsp_scraper/run_glue_crawler.py

workflows:
  version: 2.1
  daily-update:
    jobs:
      - build-and-scrape:
          context: aws
    triggers:
      - schedule:
          cron: "0 9 * * *"
          filters:
            branches:
              only:
                - master
  run-glue-crawler:
    jobs:
      - build-and-scrape:
          context: aws
      - crawl-tables:
          context: aws
          no_output_timeout: 15m
          requires:
            - build-and-scrape
